{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import packages"
      ],
      "metadata": {
        "id": "Dcc7NCl_jiSf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1yDDBjxjMpJ",
        "outputId": "2f5b9fac-b214-422c-baa8-5931c50e2765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting loralib\n",
            "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
            "Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: loralib\n",
            "Successfully installed loralib-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 install loralib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "jeGe3ISXjn8v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Data Loader"
      ],
      "metadata": {
        "id": "j6kgsUJCjp7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ6btvWsjrGE",
        "outputId": "e11ff573-ba6b-4999-aa1e-c3b3409e972f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:16<00:00, 10605594.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. LoRA"
      ],
      "metadata": {
        "id": "0cOS8m_OjvmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LoRA_Layer():\n",
        "    def __init__(\n",
        "        self,\n",
        "        r: int,\n",
        "        lora_alpha: int,\n",
        "        lora_dropout: float,\n",
        "        merge_weights: bool,\n",
        "      ):\n",
        "        self.r = r\n",
        "        self.lora_alpha = lora_alpha\n",
        "        if lora_dropout > 0:\n",
        "            self.lora_dropout = nn.Dropout(p=lora_dropout)\n",
        "        else:\n",
        "            self.lora_dropout = lambda x: x\n",
        "        self.merged = False\n",
        "        self.merge_weights = merge_weights\n",
        "\n"
      ],
      "metadata": {
        "id": "vdqWhFVKjxAY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LoRA_Linear(nn.Linear, LoRA_Layer):\n",
        "    def __init__(self, in_features: int, out_features: int, r: int = 0,\n",
        "                 lora_alpha: int = 1, lora_dropout: float =0., merge_weights: bool =True, **kwargs):\n",
        "        nn.Linear.__init__(self, in_features, out_features, **kwargs)\n",
        "        LoRA_Layer.__init__(self, r=r, lora_alpha=lora_alpha, lora_dropout=lora_dropout, merge_weights=merge_weights)\n",
        "\n",
        "        if r > 0:\n",
        "            self.lora_A = nn.Parameter(self.weight.new_zeros((r, in_features)))\n",
        "            self.lora_B = nn.Parameter(self.weight.new_zeros((out_features, r)))\n",
        "            self.scaling = self.lora_alpha / self.r\n",
        "            self.weight.requires_grad = False  # disable gradient of the original weights, from nn.Linear\n",
        "        self.reset_parameters()\n",
        "\n",
        "        def reset_parameters(self):\n",
        "            nn.Linear.reset_parameters(self) # init kaiming hee uniform weights\n",
        "            if hasattr(self, 'lora_A'):\n",
        "                nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
        "                nn.init.zeros_(self.lora_B)\n",
        "\n",
        "        def train(self, mode:bool = True):\n",
        "            nn.Linear.train(self, mode)\n",
        "\n",
        "            # Training mode: subtract lora from the weights if they are merged\n",
        "            if mode:\n",
        "                if self.merge_weights and self.merged:\n",
        "                    if self.r > 0:\n",
        "                        self.weight.data -= (self.lora_B @ self.lora_A) * self.scaling\n",
        "                    self.merged = False\n",
        "\n",
        "            # Evaluation mode: adds lora to the weights if they are not merged\n",
        "            else:\n",
        "                if self.merge_weights and not self.merged:\n",
        "                    if self.r > 0:\n",
        "                        self.weight.data += (self.lora_B @ self.lora_A) * self.scaling\n",
        "                    self.merged = True\n",
        "\n",
        "        def forward(self, x: torch.Tensor):\n",
        "            # Evaluation mode\n",
        "            if self.r > 0 and not self.merged:\n",
        "                result = F.linear(x, self.weight, bias=self.bias)\n",
        "                result += (self.lora_dropout(x) @ self.lora_A.transpose(0, 1) @ self.lora_B.transpose(0, 1)) * self.scaling\n",
        "                return result\n",
        "\n",
        "            # Training mode\n",
        "            else:\n",
        "                return F.linear(x, self.weight, bias=self.bias)\n"
      ],
      "metadata": {
        "id": "oiyl7uCxkbW4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Modeling\n",
        "\n"
      ],
      "metadata": {
        "id": "3SUV3mO7rRIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainable_params(model):\n",
        "    total_params = 0\n",
        "    for param in model.parameters():\n",
        "        if param.requires_grad:\n",
        "            total_params += param.numel()\n",
        "\n",
        "    print(f\"Trainable params: {total_params/1e6:.2f} M\")"
      ],
      "metadata": {
        "id": "1BqJ0HS_rSk1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Load pre_trained VGG16 Imagene1K\n",
        "\n"
      ],
      "metadata": {
        "id": "y0QjjUIlrZIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "vgg16_model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
        "\n",
        "vgg16_classifier_ckpt = vgg16_model.classifier.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf9Earvgrd0D",
        "outputId": "929043b5-6687-4ce8-a6fe-f4aad810ca3a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:06<00:00, 84.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params(vgg16_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVNrGdaJrfKz",
        "outputId": "e58a1bf7-5a85-4f17-e0ee-e03374e630f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 138.36 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params(vgg16_model.classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOKo3v8trhr3",
        "outputId": "7db50367-2608-45a7-b215-3108367c1225"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 123.64 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Define clf with LORA, feature extractor the same"
      ],
      "metadata": {
        "id": "4oKwnWq_ri5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_classifier =  nn.Sequential(\n",
        "    LoRA_Linear(in_features=25088, out_features=4096, bias=True, r=16),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.5, inplace=False),\n",
        "    LoRA_Linear(in_features=4096, out_features=4096, bias=True, r=16),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.5, inplace=False),\n",
        "    LoRA_Linear(in_features=4096, out_features=1000, bias=True, r=16)\n",
        ")"
      ],
      "metadata": {
        "id": "p7emqanjrlzL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3: Load pretrained weights to LORA_CLF"
      ],
      "metadata": {
        "id": "_FUUh4TCrqlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_classifier.load_state_dict(vgg16_classifier_ckpt, strict=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJYrvZ5xrurh",
        "outputId": "01a73cf4-eed8-463e-e02a-ad76e89067d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['0.lora_A', '0.lora_B', '3.lora_A', '3.lora_B', '6.lora_A', '6.lora_B'], unexpected_keys=[])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4: Add a layer with output features is 10 for CIFAR10"
      ],
      "metadata": {
        "id": "DJfxGawUryPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_classififer = nn.Sequential(\n",
        "    *lora_classifier,\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.5, inplace=False),\n",
        "    LoRA_Linear(in_features=1000, out_features=10, bias=True)\n",
        ")"
      ],
      "metadata": {
        "id": "fJrqTUulrx4o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params(new_classififer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRWY2uhEr412",
        "outputId": "9447660a-1cf5-4e25-985d-441bb7462ffe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 0.70 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 Wrap pre-trained VGG16 features (will be frozen) with LoRA classifier"
      ],
      "metadata": {
        "id": "DFoURRPar7eU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CLS_model(nn.Module):\n",
        "    def __init__(self)->None:\n",
        "        super().__init__()\n",
        "        self.features = vgg16_model.features.eval()\n",
        "        for param in self.features.parameters():\n",
        "            param.requires_grad_(False)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.classifier = new_classififer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "LMoUmj0qr8So"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CLS_model().to(device)"
      ],
      "metadata": {
        "id": "QoR5o6xqsP65"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE1ZkYxNsQxR",
        "outputId": "4a69c6fa-96bf-4366-f502-c17006bcb332"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 0.70 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training baby"
      ],
      "metadata": {
        "id": "-yptjEUssRwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "THqzF6IAsT2q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "\n",
        "start = time.time()\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{10}], Average Loss: {running_loss / len(trainloader):.4f}, GPU used: {torch.cuda.memory_allocated(0)/1e9:.2f} G')\n",
        "\n",
        "print('Finished Training')\n",
        "print(f'Training time: {time.time() - start:.2f} s')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdE8xvvVsU_F",
        "outputId": "026bd601-722f-4b3a-dfbd-9b0741b32fee"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Average Loss: 1.7969, GPU used: 0.58 G\n",
            "Epoch [2/10], Average Loss: 1.4651, GPU used: 0.58 G\n",
            "Epoch [3/10], Average Loss: 1.4387, GPU used: 0.58 G\n",
            "Epoch [4/10], Average Loss: 1.4310, GPU used: 0.58 G\n",
            "Epoch [5/10], Average Loss: 1.4288, GPU used: 0.58 G\n",
            "Epoch [6/10], Average Loss: 1.4216, GPU used: 0.58 G\n",
            "Epoch [7/10], Average Loss: 1.4173, GPU used: 0.58 G\n",
            "Epoch [8/10], Average Loss: 1.4115, GPU used: 0.58 G\n",
            "Epoch [9/10], Average Loss: 1.4077, GPU used: 0.58 G\n",
            "Epoch [10/10], Average Loss: 1.3978, GPU used: 0.58 G\n",
            "Finished Training\n",
            "Training time: 209.59 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Eval\n"
      ],
      "metadata": {
        "id": "rn0fKUfHsXZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the model on the 10000 test images: {100 * correct / total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eBVqSEXsYil",
        "outputId": "7666cee8-ea35-4304-9dec-8297b66fafed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 10000 test images: 56.61 %\n"
          ]
        }
      ]
    }
  ]
}