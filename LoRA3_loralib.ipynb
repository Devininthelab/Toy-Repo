{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP2cBkmpa+qsefkH6ETICG+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devininthelab/Toy-Repo/blob/main/LoRA3_loralib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import packages"
      ],
      "metadata": {
        "id": "_8_hF3fEyhw2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYKdvp9uvYGm",
        "outputId": "d65b8c23-5a08-4609-eed0-9e439af96c67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting loralib\n",
            "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
            "Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: loralib\n",
            "Successfully installed loralib-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 install loralib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "wzfz8rriykFs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Dataloader"
      ],
      "metadata": {
        "id": "8--f2lF5ylsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKXHqc4Uynfq",
        "outputId": "5fa6539b-57dc-4978-fd83-8eb9a4874b9d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:19<00:00, 8625733.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Modeling"
      ],
      "metadata": {
        "id": "ScVHOc1KypTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainable_params(model):\n",
        "    total_params = 0\n",
        "    for param in model.parameters():\n",
        "        if param.requires_grad:\n",
        "            total_params += param.numel()\n",
        "\n",
        "    print(f\"Trainable params: {total_params/1e6:.2f} M\")"
      ],
      "metadata": {
        "id": "f0YmcmxGyqAJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Load pretrained weight Imagenet1k"
      ],
      "metadata": {
        "id": "ntxGlkBmyrfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "vgg16_model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
        "\n",
        "vgg16_classifier_ckpt = vgg16_model.classifier.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKfljrJPyvfO",
        "outputId": "ee4713e9-f8a8-46c5-bd18-36985abf5b8d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:05<00:00, 100MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params(vgg16_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5puOxIoMyx2S",
        "outputId": "2cbc2d9a-106b-47f1-e6d4-fb60ba974df1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 138.36 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params(vgg16_model.classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Innt9QTvyy9W",
        "outputId": "5c9f8157-bcf3-4d73-d740-8e8d2703a7c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 123.64 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Define LORA"
      ],
      "metadata": {
        "id": "Os8B0Rw_yz4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import loralib\n",
        "\n",
        "lora_classifier =  nn.Sequential(\n",
        "    loralib.Linear(in_features=25088, out_features=4096, bias=True, r=16),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.5, inplace=False),\n",
        "    loralib.Linear(in_features=4096, out_features=4096, bias=True, r=16),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.5, inplace=False),\n",
        "    loralib.Linear(in_features=4096, out_features=1000, bias=True, r=16)\n",
        ")"
      ],
      "metadata": {
        "id": "PvQnRka3y1K0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3: Load pre_trained weights to LoRA clf"
      ],
      "metadata": {
        "id": "zfHeZ-Epy52I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_classifier.load_state_dict(vgg16_classifier_ckpt, strict=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-DZRetMy4vS",
        "outputId": "bb5faa11-a354-43dd-f061-07b767c3c37d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['0.lora_A', '0.lora_B', '3.lora_A', '3.lora_B', '6.lora_A', '6.lora_B'], unexpected_keys=[])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4: Add output for cifar10"
      ],
      "metadata": {
        "id": "u5fFvvczzEY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_classififer = nn.Sequential(\n",
        "    *lora_classifier,\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.5, inplace=False),\n",
        "    loralib.Linear(in_features=1000, out_features=10, bias=True)\n",
        ")"
      ],
      "metadata": {
        "id": "p3HdYBJTzHxg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params(new_classififer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvCLHmq-zKiL",
        "outputId": "fdbb117f-d3c1-46b1-89c9-14cf4dbc4e86"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 0.70 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5: Wrap with fe"
      ],
      "metadata": {
        "id": "hPQmmZF4zLne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CLS_model(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.features = vgg16_model.features.eval()\n",
        "        for param in self.features.parameters():\n",
        "            param.requires_grad_(False)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.classifier = new_classififer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "UZMikT5HzNaQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CLS_model().to(device)"
      ],
      "metadata": {
        "id": "R_ru0qorzPkj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ytQCt44zRP3",
        "outputId": "a3493a8d-8ec3-4d8c-df49-45ccd7edbbd9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 0.70 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training"
      ],
      "metadata": {
        "id": "8_m77_0WzR-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "804UHc6SzTu6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "\n",
        "start = time.time()\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{10}], Average Loss: {running_loss / len(trainloader):.4f}, GPU used: {torch.cuda.memory_allocated(0)/1e9:.2f} G')\n",
        "\n",
        "print('Finished Training')\n",
        "print(f'Training time: {time.time() - start:.2f} s')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvEohSczzWqh",
        "outputId": "4e723ed2-0b9a-4b3b-aba6-f5680f43b060"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Average Loss: 1.5450, GPU used: 0.59 G\n",
            "Epoch [2/10], Average Loss: 1.2925, GPU used: 0.59 G\n",
            "Epoch [3/10], Average Loss: 1.2137, GPU used: 0.59 G\n",
            "Epoch [4/10], Average Loss: 1.1491, GPU used: 0.59 G\n",
            "Epoch [5/10], Average Loss: 1.1118, GPU used: 0.59 G\n",
            "Epoch [6/10], Average Loss: 1.0814, GPU used: 0.59 G\n",
            "Epoch [7/10], Average Loss: 1.0606, GPU used: 0.59 G\n",
            "Epoch [8/10], Average Loss: 1.0339, GPU used: 0.59 G\n",
            "Epoch [9/10], Average Loss: 1.0120, GPU used: 0.59 G\n",
            "Epoch [10/10], Average Loss: 1.0029, GPU used: 0.59 G\n",
            "Finished Training\n",
            "Training time: 215.79 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Eval"
      ],
      "metadata": {
        "id": "fkhe9k-wzXuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the model on the 10000 test images: {100 * correct / total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKXwOxelzZkw",
        "outputId": "d9a259fa-38e0-4c6c-bbb9-5fe211acbc01"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 10000 test images: 65.1 %\n"
          ]
        }
      ]
    }
  ]
}